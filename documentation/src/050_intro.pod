=head1 Introduction

Here we explain some of the background leading up to the next generation sakai
and briefly introducing some of the main points of the new system.

=head2 The background to the next generation sakai.

The next generation sakai heralds a new content driven approach, but what does
this mean and why would anyone want it? Well, simply the quality and ease of
manipulation of content has emerged as a limiting factor of usefulness for an
enterprise learning management or virtual research system. With current sakai,
the site silo system makes it cumbersome to share, edit, merge, update, remove,
or annotate content in a way that could be consistent across multiple sites,
thus limiting content re-use and potentially duplicating effort in many places.

=head2 So why not just re-engineer the sakai content management engine?

If only it were that easy! The content hosting service has grown up to be a
very complex body of code that even those most familiar with find it difficult
to extend or alter.

Furthermore, learning the finer details of a complex, proprietary content
management system is not a skill that can be easily transferred to other often
very different content management systems.  So developers have little to gain
by spending hours getting to grips with sakai's particular flavour of content
management with its unique terminologies and programming interfaces.

It's non-standard nature is also problematic for day to day sakai operation,
with no community wide accepted best practice on content backup, for example.
This means the content backup for an institution may be inconsistent with their
latest database backup. It also requires a complex approach to maintain
consistency of the indexes used for searching content. The sakai webdav
implementation also lacks wider standardization meaning interoperability across
webdav clients is at best variable.

Interoperability and re-use of the sakai content management system with and by
other software systems is also limited since porting those applications to work
with a non-standard system is often prohibitively costly. For example, an
independent company might have a really great survey tool, but there is no
desire or incentive for them to port their code to work on top of sakai. In the
absense of a standardized approach, developing services on top of a single
vendor's repository API would be a risky business.

Thus, the maintenance and integration of the existing sakai content management
system has become increasingly expensive.

=head2 Enter JSR-170 (and JSR-283)

The solution to these problems is to adopt a much more standardized content
repository model. The Content Repository API for Java Technology (aka JSR-170)
specification, developed under the Java Community Process (JCP) program, aims
to achieve just that.

The JSR-170 API defines the interaction between an application and a content
repository in terms of various content services. The versioning service of a
content repository, for example, are clearly defined so an application knows
how to browse version history, check in and check out content items, or update
and merge content in a standard fashion. The query service, as another example,
allows standardized searching of a compliant repository by an application
without negotiating proprietary search APIs and languages.

JSR-170 promises the Java world, and hence the predominantly java based sakai
system, a unified API that allows access to a compliant repository in a vendor-
or implementation-neutral fashion. Thus the next generation sakai should be
equally happy running on top of any compliant JSR-170 system whether that is
Apache Jackrabbit, Xythos, or a new system yet to emerge.

JSR-170 offers the potential for true content repository infrastructure that
independent application developers can use to create applications on, without
any partner fees or commercial association. Thus, empowering our example survey
tool provider to port their application to run on sakai with confidence that
the work will be much more likely reusable on other systems also.

=head2 Why is this such a good thing?

For the sakai developer, JSR-170 brings a well-designed single API to work from
removing worry about which vendor repository drives sakai. Skills acquired
developing for a JSR-170 compliant repository transfer to all other such
repositories. Code will be more portable, not requiring a re-write for every
implementation requiring a different repository. Standardization also typically
means richer development tools such as Eclipse plug-ins. Furthermore, the
Apache Software Foundation's JSR-170 reference implementation, "Jackrabbit",
gives developers access to an open-source, fully JSR-170 compliant content
repository, without having to negotiate licensing details, enabling faster
content application development commencement.

The wider use of a standardized content system will mean functionality such as
WebDAV has wider use and therefore testing. Standard approaches mean production
issues will be more widely addressed. Future versions of jackrabbit are
expected to allow hot backups and native clustering via a next generation
persistence model. (http://jackrabbit.apache.org/jackrabbit-roadmap.html).

Ultimately the burden of maintaining the sakai content management system will
usefully fall away from the sakai community into a competitive environment
where there is real choice, including a viable "free" option. Leaving the sakai
community to focus on producing a world class learning environment with less
distraction and complexity.

=head2 Other intended benefits of the next generation sakai

The next generation sakai will provide a core set of functionality to manage
users, content, sites, and tools and the associated authorization. Here we
outline some of the intended attributes of the new system. Note: these are aims
rather than cast iron guarantees!

The aim is to have at least 80% code test coverage (in terms of lines and
scenarios by unit tests run on every sakai build) with good documentation. REST
based interfaces on to core APIs will allow further automated testing and
quality assurance.

The next generation sakai will provide a platform which allows for more
flexible arrangements of content and activities, resulting in a richer field
for usability improvements, and which will also be more resilient and scalable
to drive down the cost of deployment. The next generation sakai will lower the
cost of maintenance, in terms of development effort required, and will lower
the difficulty (in terms of manhours) for both mainstream and niche
developments. Where possible, 3rd party systems/code will be used to minimise
the custom code base.

As well as the following improvements detailed below, the next generation sakai
will use improved project processes to ensure clear documentation, rapid and
efficient development and accountability.

=head3 Scalability

At least 2k users per instance with session state sharing between nodes.
Unloaded all requests will take < 10ms. Session storage will be <20K. 90% of
the traffic between the UI and the server will be hyper efficient HTTP GET's.

=head3 Easier and Quicker to use

A java developer will be able to get up and running in < 30 minutes after
downloading, as a sakai developer or user.  Eclipse artifacts will be removed
from SVN. Tools will supply their own scripts for special configuration
needs, eg adding local libraries to classpath. There will be no critical
"Problems" in the Eclipse build.

=head3 Flexible, User Centered Structure

Unbind objects from the site structure to make them shareable between
contexts and owned by individuals. Where appropriate content objects
will be referenced by URI and stored in a form suitable for use in
the client (eg JSON files on disk for use by Javascript).
Requirements are User Centered Data Requirements

=head3 Offline friendly

The next generation sakai will not prevent development of an offline client system,
even if the offline client is not available at this time

=head3 User privacy and presence

The next generation sakai will support enhanced presence. Presence in a site or within
Sakai will be able to update at an appropriate rate without
unacceptable load. Users will be able to select high privacy
(visible only to those who are organising their teaching/research
work, or to everyone, or to  groups with different levels of privacy)

=head3 Object focused permissions

Attach permissions to Objects and provide a scalable (technical and
human) mechanism for managing those permissions.

=head3 Upgrade Pathway

A mechanism will exist by which existing sakai installations can be migrated
across to a next generation sakai installation.

=head3 Build quality

The infrastructure for development of the next generation of sakai will drive
build quality by enforcing use of good practice for test and documentation
(style, javadocs, findbugs).

=head3 Better transaction management

Transactions will be managed on a scoped basis with mechanisms for
building a transaction scope in request (the default) or on demand.

=head3 Security

The next generation of sakai will build on the current excellent reputation of
the sakai system for being a reliably secure system.

=head3 Flexible partitioning of users and administrative control

An example use case being a commercial multi-tenancy setup. Specific
features would be:

=over

=item the ability to put users into (organisation) sets;

=item different user sets would not see joinable sites in other sets (except by
override);

=item administrators of user set A cannot administer users in set B or sites
designated as available to set B only. Admin screens would be unaware of sites,
etc, that were designated as belonging to another set;

=item templates, themes, etc. could be restricted to and editable by single set
members only;

=item host/provider access should be possible for support;

=item content available to set A should be securely protected from access by
members of set B (unless overridden);

=item however set B members will form a 'known group' and could be exposed to
admins in set A as an group to whom (e.g. guest access) certain permissions can
be granted.

=back
