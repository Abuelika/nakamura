=head1 The next generation of Sakai

=head2 A reference guide:

Compiled by Daniel Parry, CARET, daniel@caret.cam.ac.uk


=ff


=head1 The Next Generation of Sakai. A reference guide:

=head2 Table Of Contents

=head3 Introduction ... Page 4

=over

=item The background to the next generation sakai.

=item So why not just re-engineer the sakai content management engine?

=item Enter JSR-170 (and JSR-283)

=item Why is this such a good thing?

=item Other intended benefits of the next generation sakai

=item Scalability

=item Easier and Quicker to use

=item Flexible, User Centered Structure

=item Offline friendly

=item User privacy and presence

=item Object focused permissions

=item Upgrade Pathway

=item Build quality

=item Better transaction management

=item Security

=item Flexible partitioning of users and administrative control

=back

=head3 System Architecture ... Page 7

=over

=item Apache Sling

=item Apache Jackrabbit

=item Everything is Content!

=item MySQL

=item OSGi and Apache Felix

=item Bundles

=item Pax Web

=item Jetty

=item Apache HTTPd

=back

=head3 Building ... Page 9

=over

=item The build environment

=item Appendix A: Build script used to build the next generation sakai:

=back

=head3 Deploying ... Page 12

=over

=item Accessing the next generation sakai directly via built in jetty

=item Startup switches for the next generation sakai

=item Load balancing behind apache httpd server

=back

=head3 Developing ... Page 14

=over

=item Using git

=item github

=item Forking

=item Fetching other forks

=item Git pre-commit hook

=back

=head3 Content ... Page 15

=over

=item Sling Content and processing of content

=item Manipulating Content: The SlingPostServlet

=back

=head3 Authorization ... Page 16

=over

=item Building on Jackrabbit

=item Sling Authz Implementation Plan

=item Jackrabbit User manager

=item New Bundle for a ResourceProvider and Sling Post Operations for interacting with the jackrabbit UserManager

=item Jackrabbit 15/Sling UserManager Services

=back

=head3 REST ... Page 17

=over

=item RESTful web services

=item JSON

=item REST web services provided by Sakai

=back

=head3 User Interface ... Page 18



=ff


=head1 Introduction

Here we explain some of the background leading up to the next generation sakai
and briefly introducing some of the main points of the new system.

=head2 The background to the next generation sakai.

The next generation sakai heralds a new content driven approach, but what does
this mean and why would anyone want it? Well, simply the quality and ease of
manipulation of content has emerged as a limiting factor of usefulness for an
enterprise learning management or virtual research system. With current sakai,
the site silo system makes it cumbersome to share, edit, merge, update, remove,
or annotate content in a way that could be consistent across multiple sites,
thus limiting content re-use and potentially duplicating effort in many places.

=head2 So why not just re-engineer the sakai content management engine?

If only it were that easy! The content hosting service has grown up to be a
very complex body of code that even those most familiar with find it difficult
to extend or alter.

Furthermore, learning the finer details of a complex, proprietary content
management system is not a skill that can be easily transferred to other often
very different content management systems.  So developers have little to gain
by spending hours getting to grips with sakai's particular flavour of content
management with its unique terminologies and programming interfaces.

It's non-standard nature is also problematic for day to day sakai operation,
with no community wide accepted best practice on content backup, for example.
This means the content backup for an institution may be inconsistent with their
latest database backup. It also requires a complex approach to maintain
consistency of the indexes used for searching content. The sakai webdav
implementation also lacks wider standardization meaning interoperability across
webdav clients is at best variable.

Interoperability and re-use of the sakai content management system with and by
other software systems is also limited since porting those applications to work
with a non-standard system is often prohibitively costly. For example, an
independent company might have a really great survey tool, but there is no
desire or incentive for them to port their code to work on top of sakai. In the
absense of a standardized approach, developing services on top of a single
vendor's repository API would be a risky business.

Thus, the maintenance and integration of the existing sakai content management
system has become increasingly expensive.

=head2 Enter JSR-170 (and JSR-283)

The solution to these problems is to adopt a much more standardized content
repository model. The Content Repository API for Java Technology (aka JSR-170)
specification, developed under the Java Community Process (JCP) program, aims
to achieve just that.

The JSR-170 API defines the interaction between an application and a content
repository in terms of various content services. The versioning service of a
content repository, for example, are clearly defined so an application knows
how to browse version history, check in and check out content items, or update
and merge content in a standard fashion. The query service, as another example,
allows standardized searching of a compliant repository by an application
without negotiating proprietary search APIs and languages.

JSR-170 promises the Java world, and hence the predominantly java based sakai
system, a unified API that allows access to a compliant repository in a vendor-
or implementation-neutral fashion. Thus the next generation sakai should be
equally happy running on top of any compliant JSR-170 system whether that is
Apache Jackrabbit, Xythos, or a new system yet to emerge.

JSR-170 offers the potential for true content repository infrastructure that
independent application developers can use to create applications on, without
any partner fees or commercial association. Thus, empowering our example survey
tool provider to port their application to run on sakai with confidence that
the work will be much more likely reusable on other systems also.

=head2 Why is this such a good thing?

For the sakai developer, JSR-170 brings a well-designed single API to work from
removing worry about which vendor repository drives sakai. Skills acquired
developing for a JSR-170 compliant repository transfer to all other such
repositories. Code will be more portable, not requiring a re-write for every
implementation requiring a different repository. Standardization also typically
means richer development tools such as Eclipse plug-ins. Furthermore, the
Apache Software Foundation's JSR-170 reference implementation, "Jackrabbit",
gives developers access to an open-source, fully JSR-170 compliant content
repository, without having to negotiate licensing details, enabling faster
content application development commencement.

The wider use of a standardized content system will mean functionality such as
WebDAV has wider use and therefore testing. Standard approaches mean production
issues will be more widely addressed. Future versions of jackrabbit are
expected to allow hot backups and native clustering via a next generation
persistence model. (http://jackrabbit.apache.org/jackrabbit-roadmap.html).

Ultimately the burden of maintaining the sakai content management system will
usefully fall away from the sakai community into a competitive environment
where there is real choice, including a viable "free" option. Leaving the sakai
community to focus on producing a world class learning environment with less
distraction and complexity.

=head2 Other intended benefits of the next generation sakai

The next generation sakai will provide a core set of functionality to manage
users, content, sites, and tools and the associated authorization. Here we
outline some of the intended attributes of the new system. Note: these are aims
rather than cast iron guarantees!

The aim is to have at least 80% code test coverage (in terms of lines and
scenarios by unit tests run on every sakai build) with good documentation. REST
based interfaces on to core APIs will allow further automated testing and
quality assurance.

The next generation sakai will provide a platform which allows for more
flexible arrangements of content and activities, resulting in a richer field
for usability improvements, and which will also be more resilient and scalable
to drive down the cost of deployment. The next generation sakai will lower the
cost of maintenance, in terms of development effort required, and will lower
the difficulty (in terms of manhours) for both mainstream and niche
developments. Where possible, 3rd party systems/code will be used to minimise
the custom code base.

As well as the following improvements detailed below, the next generation sakai
will use improved project processes to ensure clear documentation, rapid and
efficient development and accountability.

=head3 Scalability

At least 2k users per instance with session state sharing between nodes.
Unloaded all requests will take < 10ms. Session storage will be <20K. 90% of
the traffic between the UI and the server will be hyper efficient HTTP GET's.

=head3 Easier and Quicker to use

A java developer will be able to get up and running in < 30 minutes after
downloading, as a sakai developer or user.  Eclipse artifacts will be removed
from SVN. Tools will supply their own scripts for special configuration
needs, eg adding local libraries to classpath. There will be no critical
"Problems" in the Eclipse build.

=head3 Flexible, User Centered Structure

Unbind objects from the site structure to make them shareable between
contexts and owned by individuals. Where appropriate content objects
will be referenced by URI and stored in a form suitable for use in
the client (eg JSON files on disk for use by Javascript).
Requirements are User Centered Data Requirements

=head3 Offline friendly

The next generation sakai will not prevent development of an offline client system,
even if the offline client is not available at this time

=head3 User privacy and presence

The next generation sakai will support enhanced presence. Presence in a site or within
Sakai will be able to update at an appropriate rate without
unacceptable load. Users will be able to select high privacy
(visible only to those who are organising their teaching/research
work, or to everyone, or to  groups with different levels of privacy)

=head3 Object focused permissions

Attach permissions to Objects and provide a scalable (technical and
human) mechanism for managing those permissions.

=head3 Upgrade Pathway

A mechanism will exist by which existing sakai installations can be migrated
across to a next generation sakai installation.

=head3 Build quality

The infrastructure for development of the next generation of sakai will drive
build quality by enforcing use of good practice for test and documentation
(style, javadocs, findbugs).

=head3 Better transaction management

Transactions will be managed on a scoped basis with mechanisms for
building a transaction scope in request (the default) or on demand.

=head3 Security

The next generation of sakai will build on the current excellent reputation of
the sakai system for being a reliably secure system.

=head3 Flexible partitioning of users and administrative control

An example use case being a commercial multi-tenancy setup. Specific
features would be:

=over

=item the ability to put users into (organisation) sets;

=item different user sets would not see joinable sites in other sets (except by
override);

=item administrators of user set A cannot administer users in set B or sites
designated as available to set B only. Admin screens would be unaware of sites,
etc, that were designated as belonging to another set;

=item templates, themes, etc. could be restricted to and editable by single set
members only;

=item host/provider access should be possible for support;

=item content available to set A should be securely protected from access by
members of set B (unless overridden);

=item however set B members will form a 'known group' and could be exposed to
admins in set A as an group to whom (e.g. guest access) certain permissions can
be granted.

=back


=ff


=head1 System Architecture

=head2 Apache Sling

The next generation of sakai will be built on top of the first enterprise-level
web framework dedicated to JSR-170 Java Content Repositories, the Apache
incubation project Sling (http://incubator.apache.org/sling/). Sling is a web
framework that uses a Java Content Repository, by default Apache Jackrabbit, to
store and manage content.

=head2 Apache Jackrabbit

The main purpose of Sling is to develop a content-centric Web Application
framework for Java Content Repository (JCR) based data stores. Sling is
implemented - with the notable exception of JCR Node Type management - purely
in terms of the JCR API and as such may use any JCR compliant repository. The
default implementation for Apache Jackrabbit is provided out of the box.

=head2 Everything is Content!

The mantra for JackRabbit is that everything is content but what impact does
this have on the next generation sakai architecture? Well, entities are no
longer persisted and retrieved from database tables but rather content nodes are
retrieved from a hierarchy within a JCR repository and indexed using carefully
designed views. These data heirarchies need to be designed carefully to avoid
excessive complexity and maintain efficiency. JCR directories containing too
many nodes have degraded write performance but careful design can avoid this.

Treating Sakai deployments as content stores rather than models of entities
implies they result from an authoring effort. On site creation a user decides
on a site name and access roles required. This translates to authoring a site's
meta content. As site information is added, assignments, quizzes, resources,
students, etc, these become site related content nodes. Thus, sakai content
grows as sites are created and content added. Considering all data as
hierarchical content enables elegant handling of content access and security.
Each content node has an associated Access Control List (ACL) inheritable from
parent nodes just like a file system.

=head2 MySQL

Jackrabbit can be configured as usual via the repository.xml file to use a
different backend from the default derby DB option. This should enable
clustering of the jackrabbit repo though wore work is needed to investigate
Sling clustering in general.

=head2 OSGi and Apache Felix

Whilst Sling is not an OSGi framework implementation specific application, it
features an embedded Apache Felix OSGi framework and console that provides a
dynamic runtime environment, where code and content bundles can be loaded,
unloaded and reconfigured at runtime. It is expected that Sling will also
operate inside other OSGi frameworks such as Equinox and Knopflerfish.

=head2 Bundles

Sling itself is implemented as a series of OSGi Bundles and makes extensive use
of the OSGi functionality, such as lifecycle management and the service layer.
The next generation sakai builds further upon this principle adding extra
functionality to an already feature rich system. Also, whilst OSGi
provides an HTTP Service this is further extended by the Pax Web bundle.

=head2 Pax Web

Pax Web (http://wiki.ops4j.org/display/paxweb/Pax+Web) is an OSGi R4 Http
Service implementation using Jetty. It extends OSGi Http Service with better
servlet support, filters, listeners, error pages and JSPs and some others in
order to meet the latest versions of Servlet specs.

=head2 Jetty

Jetty (http://www.mortbay.org/jetty/) is an open-source project providing a
100% java based standards compliant HTTP server, HTTP client and javax.servlet
container. It can be used as the entry point to the next generation sakai
application, or can be mounted behind an apache httpd front end.

=head2 Apache HTTPd

The Apache HTTPd implementation is an open-source HTTP server for modern
operating systems including UNIX and Windows NT. The implementation provides a
secure, efficient and extensible server that provides HTTP services in sync
with the current HTTP standards. It can act as a reliable front end to the next
generation sakai and bring additional load balancing capability as well as SSL
support and super fast static content serving.


=ff


=head1 Building

Building the next generation sakai differs from how building the current sakai
works. This document details the required build environment and steps:

=head2 The build environment

To build the next generation sakai you will need to have a subversion client, a
git client, java, and maven installed. In particular, JDK 5, e.g. java version
"1.5.0_17" and maven 2.0.7 or above since sling specifies a prerequisite of
maven 2.0.7, e.g. mvn -v should return something like: Maven version: 2.0.9.
There are instructions about upgrading maven on Mac OS X here:
http://steve-on-sakai.blogspot.com/2009/04/updating-maven-on-mac-os-x.html

Currently the trunk version of Sling is required and the source will need to be
fetched and built. Note, full details are available here:
http://incubator.apache.org/sling/site/project-information.html

$ svn co http://svn.eu.apache.org/repos/asf/incubator/sling/trunk sling;

$ pushd sling;

$ mvn -s /dev/null clean install;

This build will populate the maven repo with some required files for the next
generation sakai, so it is important that all builds are performed as the same
user.

For those who prefer git, there is also a git repo of the sling source at
http://git.apache.org/sling.git

The python and ruby scripting engines also need to be built to further populate
the local maven repo:

$ pushd contrib;

$ mvn -s /dev/null clean install;

The code for the next generation sakai is hosted at github. You do not need an
account, however, to clone it (git terminology for svn checkout in effect) and
you can subsequently run git pull to keep your local version up to date:

$ git clone git://github.com/ieb/open-experiments.git

$ cd open-experiments/slingtests/osgikernel;

$ mvn -s /dev/null clean install;

If that completes successfully, then you now have the next generation sakai
built! You should now be able to run:

$ java -jar app/target/org.sakaiproject.kernel2.osgi.app-0.1-SNAPSHOT.jar

Note: this will create a 'sling/' directory in the current working directory,
which will contain configurations and run time data. If you make alterations or
changes to the code you may well want to remove the sling directory and have it
rebuilt to ensure a clean build.

=head2 Appendix A: Build script used to build the next generation sakai:

The following script is available from:
https://saffron.caret.cam.ac.uk/svn/projects/sakaibuilds/trunk/scripts/build_sling.sh

#!/bin/sh

# Build return code: 0 denotes a success; anything else a failure.

EXITCODE=0;

pushd sling;

echo "Starting maven build of sling.";

mvn -s /dev/null clean install;

EXITCODE=${?};

if [ "${EXITCODE}" != "0" ] ; then

echo "ERROR: Problem with build, exit code was ${EXITCODE}";

exit ${EXITCODE};

fi

pushd contrib;

echo "Starting maven build of sling contrib.";

mvn -s /dev/null clean install;

EXITCODE=${?};

if [ "${EXITCODE}" != "0" ] ; then

echo "ERROR: Problem with build, exit code was ${EXITCODE}";

exit ${EXITCODE};

fi

popd;

popd;

if [ ! -d open-experiments ] ; then

git clone git://github.com/ieb/open-experiments.git

fi

if [ ! -d open-experiments ] ; then

echo "ERROR: git clone should have created directory open-experiments, aborting!";

exit 1;

fi

pushd open-experiments;

git pull;

pushd slingtests;

pushd osgikernel;

echo "Starting maven build of open-experiments.";

mvn -s /dev/null clean install;

EXITCODE=${?};

if [ "${EXITCODE}" != "0" ] ; then

echo "ERROR: Problem with build, exit code was ${EXITCODE}";

exit ${EXITCODE};

fi

popd;

popd;

popd;

exit ${EXITCODE};


=ff


=head1 Deploying

Once built (See the chapter on building), there will be the following jar
available: app/target/org.sakaiproject.kernel2.osgi.app-0.1-SNAPSHOT.jar.

=head2 Accessing the next generation sakai directly via built in jetty

The built jar can be transferred to a production server and run via:

$ java -server -Xms256m -Xmx1500m -XX:MaxPermSize=64m -Djava.awt.headless=true -Duser.timezone=Europe/London -jar app/target/org.sakaiproject.kernel2.osgi.app-0.1-SNAPSHOT.jar

This will start up a Jetty web server (http://www.mortbay.org/) HTTP listener
on port 8080, which a local web browser can access via http://localhost:8080,
for example. The -server option selects the server JVM, -Xms and -Xmx specify
the minimum and maximum heap sizes respectively - you'll want to tailor these
for your particular hardware setup, -XX:MaxPermSize specifies a maximum perm
size, -Djava.awt.headless=true selects headless mode - a system configuration
which assumes the display device, keyboard, or mouse are lacking,
-Duser.timezone=Europe/London sets an appropriate timezone - again you'll want
to tailor this.

=head2 Startup switches for the next generation sakai

There are some further switches available when starting up, documented at
http://cwiki.apache.org/confluence/display/SLING/The+Sling+Launchpad

Examples:

-f - will log to stdout

eg

java -jar app/target/org.sakaiproject.kernel2.osgi.app-0.1-SNAPSHOT.jar -f -

-l sets the log level 0 = none, 1 = error , 2 = warn, 3 = info, 4 = debug

eg java -jar app/target/org.sakaiproject.kernel2.osgi.app-0.1-SNAPSHOT.jar -f - -l 4

and if you want to attach a debugger right at the start of startup
(suspend=y), log at debug to stdout

java -Xdebug -Xrunjdwp:transport=dt_socket,address=8000,server=y,suspend=y -jar app/target/org.sakaiproject.kernel2.osgi.app-0.1-SNAPSHOT.jar -f - -l 4 

=head2 Load balancing behind apache httpd server

There will also be an AJP listener available on port 8009. Thus, apache httpd
or another such web server can be used as a reliable and fast front end to the
next generation sakai application. The mod_jk apache httpd module will be
required, e.g. in the httpd configuration you will need:

LoadModule jk_module /usr/lib/apache2/modules/mod_jk.so

JkWorkersFile /etc/libapache2-mod-jk/workers.properties

JkLogFile /var/log/apache2/mod_jk.log

JkLogLevel info

JkLogStampFormat "[%a %b %d %H:%M:%S %Y] "

JkOptions +ForwardKeySize +ForwardURICompat -ForwardDirectories

JkRequestLogFormat "%w %V %T"

Then in the /etc/libapache2-mod-jk/workers.properties you need to define where
the next generation sakai is listening, e.g.:

worker.list=sakai

worker.localhost.port=8009

worker.localhost.host=localhost

worker.localhost.type=ajp13

worker.sakai.type=lb

worker.sakai.balanced_workers=localhost

worker.sakai.sticky_session=true

Then you can map a URL across to the next generation sakai instance, e.g.:

JkMount /* sakai


=ff


=head1 Developing

=head2 Using git

Developing the next generation sakai will rely heavily on the use of git
(http://git-scm.com/). Git is a free and open source, distributed version
control system designed to handle everything from small to very large projects
with speed and efficiency. A useful introduction is available via the Git
Community Book (http://book.git-scm.com).

On some systems, git installation may be as simple as:

$ apt-get install git-core

=head2 github

To assist in developing the next generation sakai, you will need at least one
of the free (300MB quota) accounts on github (http://github.com), where next
generation sakai development is currently taking place. Once signed up, you'll
want to configure git to know your user name and email:

$ git config --global user.name "your name"
$ git config --global user.email email@address.com

You then need to set up an ssh key and paste the public key into github.
Details can be found here: http://github.com/guides/providing-your-ssh-key. You
can test whether you have it working by doing:

ssh git@github.com

Note: the test is to git@ and not your username@!

=head2 Forking

Once you have git configured to work with github, you are ready to fork the
next generation sakai code. Log in and go to:

http://github.com/ieb/open-experiments/tree/master

where you will be able to click to fork. This gives you then your own fork of
the project. If you go to your account page and click through to the fork, you
will find a public clone URL, which you can git clone to your local machine and
alter to your hearts content. Once happy, you can commit your clone changes, e.g.:

$ git commit -a

$ git push

Then either verbally contact the development lead to do a pull, or issue a pull
request through the github interface. Subject to code review your changes will
then be in!

=head2 Fetching other forks

To fetch features from forks other than ieb master, such as those listed in the
graph at http://github.com/ieb/open-experiments/network, you need to add the
fork as a git checkout remote. First navigate to the repo github page and copy
the clone url.

In your git checkout run 'remote add <name> <clone url>'

Now you can do 'git fetch <name>'

and 'git checkout -b <branchname> <name>/master' allowing you to mix and match
features from various repos.

=head2 Git pre-commit hook

There exists a very slightly modified version of the default git pre-commit
hook at
http://sakai-kernel.googlegroups.com/web/pre-commit?gsc=zuchPAsAAABUDOR4v2gX6zt2Ox_oS8Nr,
designed to prevent checking in code with obvious whitespace problems,
additionally reporting files and line numbers for the problems.  Place the file
in your .git/hooks/ directory at the checkout top level and ensure it is
executable.


=ff


=head1 Content

=head2 Sling Content and processing of content

http://groups.google.com/group/sakai-kernel/web/sling-content-and-processing-of-content

=head2 Manipulating Content: The SlingPostServlet

http://incubator.apache.org/sling/site/manipulating-content-the-slingpostservlet.html


=ff


=head1 Authorization

=head2 Building on Jackrabbit

Authorization in the next generation sakai will, as far as is possible, use the
default authorization capabilities exposed by Sling though some customization
may be required and maintained. Authorization in Sling is in turn built on top
of functionality exposed by jackrabbit. Jackrabbit 1.5 is transitioning to the
JSR-283 AccessControlManager API implemented by the DefaultAccessManager
providing Access Control Lists that contain Access Control Entries. Each Entry
is associated with a Principal by name, that principal identifying an
Authorizable user or group via the PrincipalManager implementation.

=head2 Sling Authz Implementation Plan

http://groups.google.com/group/sakai-kernel/web/sling-authz-implementation-plan

=head2 Jackrabbit User manager

http://jackrabbit.apache.org/api/1.5/org/apache/jackrabbit/api/security/user/UserManager.html

=head2 New Bundle for a ResourceProvider and Sling Post Operations for interacting with the jackrabbit UserManager

https://issues.apache.org/jira/browse/SLING-875

=head2 Jackrabbit 15/Sling UserManager Services

http://groups.google.com/group/sakai-kernel/web/jackrabbit-15-sling-usermanager-services


=ff


=head1 REST

=head2 RESTful web services

A RESTful web service is a simple web service implemented using HTTP and
Representational State Transfer (REST) principles
(http://en.wikipedia.org/wiki/Representational_State_Transfer). Such a web
service can be thought about as a collection of resources. The definition of
such a web service can be thought of as comprising three aspects:

=over

=item The URI for the web service such as http://example.com/physics/timetables

=item The MIME type of the data supported by the web service. In the next
generation sakai, this is typically JSON, but it could be XML, YAML, or in fact
pretty much anything.

=item The set of operations supported by the web service using HTTP methods
(e.g. POST, GET, PUT or DELETE).

=back

=head2 JSON

JSON (JavaScript Object Notation) is a lightweight data-interchange format. It
is used predominantly by the next generation sakai system in order to build an
advanced user interface on top of a set of REST interfaces.

=head2 REST web services provided by Sakai

The next generation sakai harnesses the power of REST and JSON to deliver a
flexible user interface driven development model, where real user requirements
dictate functionality provision.

Furthermore, the exposure of functionality by this mechanism allows for more
realistic stress and functionality testing via automated means. Any language
with a suitable HTTP user agent can be used to supply the appropriate requests.
A set of perl libraries have been developed to support automated testing with
perl's LWP (search.cpan.org/perldoc?LWP) user agent. Currently, these scripts
and libraries can be found at:
https://saffron.caret.cam.ac.uk/svn/projects/sakoader/branches/improveGenericUse/K2Rest


=ff


=head1 User Interface

The latest version of the user interface can be fetched by doing:

$ svn co https://source.sakaiproject.org/svn/ux/branches/K2/trunk/uxportal/src/main/webapp/ dev

$ svn co https://source.sakaiproject.org/svn/ux/branches/K2/trunk/uxwidgets/src/main/webapp/ devwidgets

These folders contain static html, css, and js files and can be deployed simply
in to a web server. However, they rely on being able to communicate with the
next generation sakai via a set of well defined REST interfaces. As the system
is developed, these interfaces will become available and the process of
layering the new UI on top of the sakai system will be documented.


=ff


